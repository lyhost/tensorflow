// Code generated by protoc-gen-go. DO NOT EDIT.
// source: tensorflow/core/protobuf/eager_service.proto

package protobuf

import (
	context "context"
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	framework "github.com/tensorflow/tensorflow/tensorflow/go/core/framework"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

type RemoteTensorHandle struct {
	// The ID of the operation that produced this tensor.
	OpId int64 `protobuf:"varint,1,opt,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	// The index into the outputs of the operation that produced this tensor.
	OutputNum            int32    `protobuf:"varint,2,opt,name=output_num,json=outputNum,proto3" json:"output_num,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *RemoteTensorHandle) Reset()         { *m = RemoteTensorHandle{} }
func (m *RemoteTensorHandle) String() string { return proto.CompactTextString(m) }
func (*RemoteTensorHandle) ProtoMessage()    {}
func (*RemoteTensorHandle) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{0}
}

func (m *RemoteTensorHandle) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RemoteTensorHandle.Unmarshal(m, b)
}
func (m *RemoteTensorHandle) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RemoteTensorHandle.Marshal(b, m, deterministic)
}
func (m *RemoteTensorHandle) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RemoteTensorHandle.Merge(m, src)
}
func (m *RemoteTensorHandle) XXX_Size() int {
	return xxx_messageInfo_RemoteTensorHandle.Size(m)
}
func (m *RemoteTensorHandle) XXX_DiscardUnknown() {
	xxx_messageInfo_RemoteTensorHandle.DiscardUnknown(m)
}

var xxx_messageInfo_RemoteTensorHandle proto.InternalMessageInfo

func (m *RemoteTensorHandle) GetOpId() int64 {
	if m != nil {
		return m.OpId
	}
	return 0
}

func (m *RemoteTensorHandle) GetOutputNum() int32 {
	if m != nil {
		return m.OutputNum
	}
	return 0
}

// A proto representation of an eager operation.
type Operation struct {
	// A unique identifier for the operation. Set by the client so that the client
	// can uniquely identify the outputs of the scheduled operation.
	//
	// In the initial implementation, sending duplicate IDs has undefined
	// behaviour, but additional constraints may be placed upon this in the
	// future.
	Id     int64                 `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`
	Name   string                `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	Inputs []*RemoteTensorHandle `protobuf:"bytes,3,rep,name=inputs,proto3" json:"inputs,omitempty"`
	// Control Operation IDs that will be respected when ops are re-ordered by
	// async execution. If async execution (+ op re-ordering) is not enabled, this
	// should have no effect.
	ControlOpIds         []int64                         `protobuf:"varint,4,rep,packed,name=control_op_ids,json=controlOpIds,proto3" json:"control_op_ids,omitempty"`
	Attrs                map[string]*framework.AttrValue `protobuf:"bytes,5,rep,name=attrs,proto3" json:"attrs,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	Device               string                          `protobuf:"bytes,6,opt,name=device,proto3" json:"device,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                        `json:"-"`
	XXX_unrecognized     []byte                          `json:"-"`
	XXX_sizecache        int32                           `json:"-"`
}

func (m *Operation) Reset()         { *m = Operation{} }
func (m *Operation) String() string { return proto.CompactTextString(m) }
func (*Operation) ProtoMessage()    {}
func (*Operation) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{1}
}

func (m *Operation) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Operation.Unmarshal(m, b)
}
func (m *Operation) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Operation.Marshal(b, m, deterministic)
}
func (m *Operation) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Operation.Merge(m, src)
}
func (m *Operation) XXX_Size() int {
	return xxx_messageInfo_Operation.Size(m)
}
func (m *Operation) XXX_DiscardUnknown() {
	xxx_messageInfo_Operation.DiscardUnknown(m)
}

var xxx_messageInfo_Operation proto.InternalMessageInfo

func (m *Operation) GetId() int64 {
	if m != nil {
		return m.Id
	}
	return 0
}

func (m *Operation) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *Operation) GetInputs() []*RemoteTensorHandle {
	if m != nil {
		return m.Inputs
	}
	return nil
}

func (m *Operation) GetControlOpIds() []int64 {
	if m != nil {
		return m.ControlOpIds
	}
	return nil
}

func (m *Operation) GetAttrs() map[string]*framework.AttrValue {
	if m != nil {
		return m.Attrs
	}
	return nil
}

func (m *Operation) GetDevice() string {
	if m != nil {
		return m.Device
	}
	return ""
}

type QueueItem struct {
	// The remote executor should be able to handle either executing ops directly,
	// or releasing any unused tensor handles, since the tensor lifetime is
	// maintained by the client.
	//
	// Types that are valid to be assigned to Item:
	//	*QueueItem_HandleToDecref
	//	*QueueItem_Operation
	Item                 isQueueItem_Item `protobuf_oneof:"item"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *QueueItem) Reset()         { *m = QueueItem{} }
func (m *QueueItem) String() string { return proto.CompactTextString(m) }
func (*QueueItem) ProtoMessage()    {}
func (*QueueItem) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{2}
}

func (m *QueueItem) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueItem.Unmarshal(m, b)
}
func (m *QueueItem) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueItem.Marshal(b, m, deterministic)
}
func (m *QueueItem) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueItem.Merge(m, src)
}
func (m *QueueItem) XXX_Size() int {
	return xxx_messageInfo_QueueItem.Size(m)
}
func (m *QueueItem) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueItem.DiscardUnknown(m)
}

var xxx_messageInfo_QueueItem proto.InternalMessageInfo

type isQueueItem_Item interface {
	isQueueItem_Item()
}

type QueueItem_HandleToDecref struct {
	HandleToDecref *RemoteTensorHandle `protobuf:"bytes,1,opt,name=handle_to_decref,json=handleToDecref,proto3,oneof"`
}

type QueueItem_Operation struct {
	Operation *Operation `protobuf:"bytes,2,opt,name=operation,proto3,oneof"`
}

func (*QueueItem_HandleToDecref) isQueueItem_Item() {}

func (*QueueItem_Operation) isQueueItem_Item() {}

func (m *QueueItem) GetItem() isQueueItem_Item {
	if m != nil {
		return m.Item
	}
	return nil
}

func (m *QueueItem) GetHandleToDecref() *RemoteTensorHandle {
	if x, ok := m.GetItem().(*QueueItem_HandleToDecref); ok {
		return x.HandleToDecref
	}
	return nil
}

func (m *QueueItem) GetOperation() *Operation {
	if x, ok := m.GetItem().(*QueueItem_Operation); ok {
		return x.Operation
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*QueueItem) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*QueueItem_HandleToDecref)(nil),
		(*QueueItem_Operation)(nil),
	}
}

type QueueResponse struct {
	Shape                []*framework.TensorShapeProto `protobuf:"bytes,1,rep,name=shape,proto3" json:"shape,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *QueueResponse) Reset()         { *m = QueueResponse{} }
func (m *QueueResponse) String() string { return proto.CompactTextString(m) }
func (*QueueResponse) ProtoMessage()    {}
func (*QueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{3}
}

func (m *QueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueResponse.Unmarshal(m, b)
}
func (m *QueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueResponse.Marshal(b, m, deterministic)
}
func (m *QueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueResponse.Merge(m, src)
}
func (m *QueueResponse) XXX_Size() int {
	return xxx_messageInfo_QueueResponse.Size(m)
}
func (m *QueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_QueueResponse proto.InternalMessageInfo

func (m *QueueResponse) GetShape() []*framework.TensorShapeProto {
	if m != nil {
		return m.Shape
	}
	return nil
}

type CreateContextRequest struct {
	// Identifies the full cluster, and this particular worker's position within.
	ServerDef *ServerDef `protobuf:"bytes,1,opt,name=server_def,json=serverDef,proto3" json:"server_def,omitempty"`
	// Whether the ops on the worker should be executed synchronously or
	// asynchronously. By default, ops are executed synchronously.
	Async bool `protobuf:"varint,2,opt,name=async,proto3" json:"async,omitempty"`
	// Number of seconds to keep the context alive. If more than keep_alive_secs
	// has passed since a particular context has been communicated with, it will
	// be garbage collected.
	KeepAliveSecs int64 `protobuf:"varint,3,opt,name=keep_alive_secs,json=keepAliveSecs,proto3" json:"keep_alive_secs,omitempty"`
	// This is the version for all the ops that will be enqueued by the client.
	VersionDef *framework.VersionDef `protobuf:"bytes,4,opt,name=version_def,json=versionDef,proto3" json:"version_def,omitempty"`
	// Device attributes in the cluster
	ClusterDeviceAttributes []*framework.DeviceAttributes `protobuf:"bytes,6,rep,name=cluster_device_attributes,json=clusterDeviceAttributes,proto3" json:"cluster_device_attributes,omitempty"`
	// The ID of the created context. This is usually a randomly generated number,
	// that will be used to identify the context in future requests to the
	// service. Contexts are not persisted through server restarts.
	// This ID will be used for all future communications as well. It is essential
	// that both ends use this ID for selecting a rendezvous to get everything to
	// match.
	ContextId            uint64   `protobuf:"fixed64,7,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CreateContextRequest) Reset()         { *m = CreateContextRequest{} }
func (m *CreateContextRequest) String() string { return proto.CompactTextString(m) }
func (*CreateContextRequest) ProtoMessage()    {}
func (*CreateContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{4}
}

func (m *CreateContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextRequest.Unmarshal(m, b)
}
func (m *CreateContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextRequest.Marshal(b, m, deterministic)
}
func (m *CreateContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextRequest.Merge(m, src)
}
func (m *CreateContextRequest) XXX_Size() int {
	return xxx_messageInfo_CreateContextRequest.Size(m)
}
func (m *CreateContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextRequest proto.InternalMessageInfo

func (m *CreateContextRequest) GetServerDef() *ServerDef {
	if m != nil {
		return m.ServerDef
	}
	return nil
}

func (m *CreateContextRequest) GetAsync() bool {
	if m != nil {
		return m.Async
	}
	return false
}

func (m *CreateContextRequest) GetKeepAliveSecs() int64 {
	if m != nil {
		return m.KeepAliveSecs
	}
	return 0
}

func (m *CreateContextRequest) GetVersionDef() *framework.VersionDef {
	if m != nil {
		return m.VersionDef
	}
	return nil
}

func (m *CreateContextRequest) GetClusterDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.ClusterDeviceAttributes
	}
	return nil
}

func (m *CreateContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type CreateContextResponse struct {
	// List of devices that are locally accessible to the worker.
	DeviceAttributes     []*framework.DeviceAttributes `protobuf:"bytes,2,rep,name=device_attributes,json=deviceAttributes,proto3" json:"device_attributes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *CreateContextResponse) Reset()         { *m = CreateContextResponse{} }
func (m *CreateContextResponse) String() string { return proto.CompactTextString(m) }
func (*CreateContextResponse) ProtoMessage()    {}
func (*CreateContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{5}
}

func (m *CreateContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextResponse.Unmarshal(m, b)
}
func (m *CreateContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextResponse.Marshal(b, m, deterministic)
}
func (m *CreateContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextResponse.Merge(m, src)
}
func (m *CreateContextResponse) XXX_Size() int {
	return xxx_messageInfo_CreateContextResponse.Size(m)
}
func (m *CreateContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextResponse proto.InternalMessageInfo

func (m *CreateContextResponse) GetDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.DeviceAttributes
	}
	return nil
}

type EnqueueRequest struct {
	ContextId            uint64       `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	Queue                []*QueueItem `protobuf:"bytes,3,rep,name=queue,proto3" json:"queue,omitempty"`
	XXX_NoUnkeyedLiteral struct{}     `json:"-"`
	XXX_unrecognized     []byte       `json:"-"`
	XXX_sizecache        int32        `json:"-"`
}

func (m *EnqueueRequest) Reset()         { *m = EnqueueRequest{} }
func (m *EnqueueRequest) String() string { return proto.CompactTextString(m) }
func (*EnqueueRequest) ProtoMessage()    {}
func (*EnqueueRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{6}
}

func (m *EnqueueRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueRequest.Unmarshal(m, b)
}
func (m *EnqueueRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueRequest.Marshal(b, m, deterministic)
}
func (m *EnqueueRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueRequest.Merge(m, src)
}
func (m *EnqueueRequest) XXX_Size() int {
	return xxx_messageInfo_EnqueueRequest.Size(m)
}
func (m *EnqueueRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueRequest.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueRequest proto.InternalMessageInfo

func (m *EnqueueRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *EnqueueRequest) GetQueue() []*QueueItem {
	if m != nil {
		return m.Queue
	}
	return nil
}

type EnqueueResponse struct {
	// A single operation response for every item in the request.
	QueueResponse        []*QueueResponse `protobuf:"bytes,1,rep,name=queue_response,json=queueResponse,proto3" json:"queue_response,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *EnqueueResponse) Reset()         { *m = EnqueueResponse{} }
func (m *EnqueueResponse) String() string { return proto.CompactTextString(m) }
func (*EnqueueResponse) ProtoMessage()    {}
func (*EnqueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{7}
}

func (m *EnqueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueResponse.Unmarshal(m, b)
}
func (m *EnqueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueResponse.Marshal(b, m, deterministic)
}
func (m *EnqueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueResponse.Merge(m, src)
}
func (m *EnqueueResponse) XXX_Size() int {
	return xxx_messageInfo_EnqueueResponse.Size(m)
}
func (m *EnqueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueResponse proto.InternalMessageInfo

func (m *EnqueueResponse) GetQueueResponse() []*QueueResponse {
	if m != nil {
		return m.QueueResponse
	}
	return nil
}

type WaitQueueDoneRequest struct {
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// Ids to wait on. If empty, wait on everything currently pending.
	OpId                 []int64  `protobuf:"varint,2,rep,packed,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneRequest) Reset()         { *m = WaitQueueDoneRequest{} }
func (m *WaitQueueDoneRequest) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneRequest) ProtoMessage()    {}
func (*WaitQueueDoneRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{8}
}

func (m *WaitQueueDoneRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneRequest.Unmarshal(m, b)
}
func (m *WaitQueueDoneRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneRequest.Marshal(b, m, deterministic)
}
func (m *WaitQueueDoneRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneRequest.Merge(m, src)
}
func (m *WaitQueueDoneRequest) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneRequest.Size(m)
}
func (m *WaitQueueDoneRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneRequest.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneRequest proto.InternalMessageInfo

func (m *WaitQueueDoneRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *WaitQueueDoneRequest) GetOpId() []int64 {
	if m != nil {
		return m.OpId
	}
	return nil
}

type WaitQueueDoneResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneResponse) Reset()         { *m = WaitQueueDoneResponse{} }
func (m *WaitQueueDoneResponse) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneResponse) ProtoMessage()    {}
func (*WaitQueueDoneResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{9}
}

func (m *WaitQueueDoneResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneResponse.Unmarshal(m, b)
}
func (m *WaitQueueDoneResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneResponse.Marshal(b, m, deterministic)
}
func (m *WaitQueueDoneResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneResponse.Merge(m, src)
}
func (m *WaitQueueDoneResponse) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneResponse.Size(m)
}
func (m *WaitQueueDoneResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneResponse.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneResponse proto.InternalMessageInfo

type KeepAliveRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveRequest) Reset()         { *m = KeepAliveRequest{} }
func (m *KeepAliveRequest) String() string { return proto.CompactTextString(m) }
func (*KeepAliveRequest) ProtoMessage()    {}
func (*KeepAliveRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{10}
}

func (m *KeepAliveRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveRequest.Unmarshal(m, b)
}
func (m *KeepAliveRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveRequest.Marshal(b, m, deterministic)
}
func (m *KeepAliveRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveRequest.Merge(m, src)
}
func (m *KeepAliveRequest) XXX_Size() int {
	return xxx_messageInfo_KeepAliveRequest.Size(m)
}
func (m *KeepAliveRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveRequest.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveRequest proto.InternalMessageInfo

func (m *KeepAliveRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type KeepAliveResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveResponse) Reset()         { *m = KeepAliveResponse{} }
func (m *KeepAliveResponse) String() string { return proto.CompactTextString(m) }
func (*KeepAliveResponse) ProtoMessage()    {}
func (*KeepAliveResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{11}
}

func (m *KeepAliveResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveResponse.Unmarshal(m, b)
}
func (m *KeepAliveResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveResponse.Marshal(b, m, deterministic)
}
func (m *KeepAliveResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveResponse.Merge(m, src)
}
func (m *KeepAliveResponse) XXX_Size() int {
	return xxx_messageInfo_KeepAliveResponse.Size(m)
}
func (m *KeepAliveResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveResponse.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveResponse proto.InternalMessageInfo

type CloseContextRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextRequest) Reset()         { *m = CloseContextRequest{} }
func (m *CloseContextRequest) String() string { return proto.CompactTextString(m) }
func (*CloseContextRequest) ProtoMessage()    {}
func (*CloseContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{12}
}

func (m *CloseContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextRequest.Unmarshal(m, b)
}
func (m *CloseContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextRequest.Marshal(b, m, deterministic)
}
func (m *CloseContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextRequest.Merge(m, src)
}
func (m *CloseContextRequest) XXX_Size() int {
	return xxx_messageInfo_CloseContextRequest.Size(m)
}
func (m *CloseContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextRequest proto.InternalMessageInfo

func (m *CloseContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type CloseContextResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextResponse) Reset()         { *m = CloseContextResponse{} }
func (m *CloseContextResponse) String() string { return proto.CompactTextString(m) }
func (*CloseContextResponse) ProtoMessage()    {}
func (*CloseContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{13}
}

func (m *CloseContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextResponse.Unmarshal(m, b)
}
func (m *CloseContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextResponse.Marshal(b, m, deterministic)
}
func (m *CloseContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextResponse.Merge(m, src)
}
func (m *CloseContextResponse) XXX_Size() int {
	return xxx_messageInfo_CloseContextResponse.Size(m)
}
func (m *CloseContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextResponse proto.InternalMessageInfo

type RegisterFunctionRequest struct {
	ContextId            uint64                 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	FunctionDef          *framework.FunctionDef `protobuf:"bytes,2,opt,name=function_def,json=functionDef,proto3" json:"function_def,omitempty"`
	XXX_NoUnkeyedLiteral struct{}               `json:"-"`
	XXX_unrecognized     []byte                 `json:"-"`
	XXX_sizecache        int32                  `json:"-"`
}

func (m *RegisterFunctionRequest) Reset()         { *m = RegisterFunctionRequest{} }
func (m *RegisterFunctionRequest) String() string { return proto.CompactTextString(m) }
func (*RegisterFunctionRequest) ProtoMessage()    {}
func (*RegisterFunctionRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{14}
}

func (m *RegisterFunctionRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RegisterFunctionRequest.Unmarshal(m, b)
}
func (m *RegisterFunctionRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RegisterFunctionRequest.Marshal(b, m, deterministic)
}
func (m *RegisterFunctionRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RegisterFunctionRequest.Merge(m, src)
}
func (m *RegisterFunctionRequest) XXX_Size() int {
	return xxx_messageInfo_RegisterFunctionRequest.Size(m)
}
func (m *RegisterFunctionRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_RegisterFunctionRequest.DiscardUnknown(m)
}

var xxx_messageInfo_RegisterFunctionRequest proto.InternalMessageInfo

func (m *RegisterFunctionRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *RegisterFunctionRequest) GetFunctionDef() *framework.FunctionDef {
	if m != nil {
		return m.FunctionDef
	}
	return nil
}

type RegisterFunctionResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *RegisterFunctionResponse) Reset()         { *m = RegisterFunctionResponse{} }
func (m *RegisterFunctionResponse) String() string { return proto.CompactTextString(m) }
func (*RegisterFunctionResponse) ProtoMessage()    {}
func (*RegisterFunctionResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{15}
}

func (m *RegisterFunctionResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RegisterFunctionResponse.Unmarshal(m, b)
}
func (m *RegisterFunctionResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RegisterFunctionResponse.Marshal(b, m, deterministic)
}
func (m *RegisterFunctionResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RegisterFunctionResponse.Merge(m, src)
}
func (m *RegisterFunctionResponse) XXX_Size() int {
	return xxx_messageInfo_RegisterFunctionResponse.Size(m)
}
func (m *RegisterFunctionResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_RegisterFunctionResponse.DiscardUnknown(m)
}

var xxx_messageInfo_RegisterFunctionResponse proto.InternalMessageInfo

type SendTensorRequest struct {
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// All remote tensors are identified by <Op ID, Output num>. To mimic this
	// situation when directly sending tensors, we include an "artificial" op ID
	// (which would have corresponded to the _Recv op when not using SendTensor).
	OpId int64 `protobuf:"varint,2,opt,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	// The index within the repeated field is the output number that will help
	// uniquely identify (along with the above op_id) the particular tensor.
	Tensors []*framework.TensorProto `protobuf:"bytes,3,rep,name=tensors,proto3" json:"tensors,omitempty"`
	// The device on which the tensors should be resident.
	DeviceName           string   `protobuf:"bytes,4,opt,name=device_name,json=deviceName,proto3" json:"device_name,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SendTensorRequest) Reset()         { *m = SendTensorRequest{} }
func (m *SendTensorRequest) String() string { return proto.CompactTextString(m) }
func (*SendTensorRequest) ProtoMessage()    {}
func (*SendTensorRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{16}
}

func (m *SendTensorRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SendTensorRequest.Unmarshal(m, b)
}
func (m *SendTensorRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SendTensorRequest.Marshal(b, m, deterministic)
}
func (m *SendTensorRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SendTensorRequest.Merge(m, src)
}
func (m *SendTensorRequest) XXX_Size() int {
	return xxx_messageInfo_SendTensorRequest.Size(m)
}
func (m *SendTensorRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_SendTensorRequest.DiscardUnknown(m)
}

var xxx_messageInfo_SendTensorRequest proto.InternalMessageInfo

func (m *SendTensorRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *SendTensorRequest) GetOpId() int64 {
	if m != nil {
		return m.OpId
	}
	return 0
}

func (m *SendTensorRequest) GetTensors() []*framework.TensorProto {
	if m != nil {
		return m.Tensors
	}
	return nil
}

func (m *SendTensorRequest) GetDeviceName() string {
	if m != nil {
		return m.DeviceName
	}
	return ""
}

type SendTensorResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SendTensorResponse) Reset()         { *m = SendTensorResponse{} }
func (m *SendTensorResponse) String() string { return proto.CompactTextString(m) }
func (*SendTensorResponse) ProtoMessage()    {}
func (*SendTensorResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7f63cfa0a7bc4510, []int{17}
}

func (m *SendTensorResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SendTensorResponse.Unmarshal(m, b)
}
func (m *SendTensorResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SendTensorResponse.Marshal(b, m, deterministic)
}
func (m *SendTensorResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SendTensorResponse.Merge(m, src)
}
func (m *SendTensorResponse) XXX_Size() int {
	return xxx_messageInfo_SendTensorResponse.Size(m)
}
func (m *SendTensorResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_SendTensorResponse.DiscardUnknown(m)
}

var xxx_messageInfo_SendTensorResponse proto.InternalMessageInfo

func init() {
	proto.RegisterType((*RemoteTensorHandle)(nil), "tensorflow.eager.RemoteTensorHandle")
	proto.RegisterType((*Operation)(nil), "tensorflow.eager.Operation")
	proto.RegisterMapType((map[string]*framework.AttrValue)(nil), "tensorflow.eager.Operation.AttrsEntry")
	proto.RegisterType((*QueueItem)(nil), "tensorflow.eager.QueueItem")
	proto.RegisterType((*QueueResponse)(nil), "tensorflow.eager.QueueResponse")
	proto.RegisterType((*CreateContextRequest)(nil), "tensorflow.eager.CreateContextRequest")
	proto.RegisterType((*CreateContextResponse)(nil), "tensorflow.eager.CreateContextResponse")
	proto.RegisterType((*EnqueueRequest)(nil), "tensorflow.eager.EnqueueRequest")
	proto.RegisterType((*EnqueueResponse)(nil), "tensorflow.eager.EnqueueResponse")
	proto.RegisterType((*WaitQueueDoneRequest)(nil), "tensorflow.eager.WaitQueueDoneRequest")
	proto.RegisterType((*WaitQueueDoneResponse)(nil), "tensorflow.eager.WaitQueueDoneResponse")
	proto.RegisterType((*KeepAliveRequest)(nil), "tensorflow.eager.KeepAliveRequest")
	proto.RegisterType((*KeepAliveResponse)(nil), "tensorflow.eager.KeepAliveResponse")
	proto.RegisterType((*CloseContextRequest)(nil), "tensorflow.eager.CloseContextRequest")
	proto.RegisterType((*CloseContextResponse)(nil), "tensorflow.eager.CloseContextResponse")
	proto.RegisterType((*RegisterFunctionRequest)(nil), "tensorflow.eager.RegisterFunctionRequest")
	proto.RegisterType((*RegisterFunctionResponse)(nil), "tensorflow.eager.RegisterFunctionResponse")
	proto.RegisterType((*SendTensorRequest)(nil), "tensorflow.eager.SendTensorRequest")
	proto.RegisterType((*SendTensorResponse)(nil), "tensorflow.eager.SendTensorResponse")
}

func init() {
	proto.RegisterFile("tensorflow/core/protobuf/eager_service.proto", fileDescriptor_7f63cfa0a7bc4510)
}

var fileDescriptor_7f63cfa0a7bc4510 = []byte{
	// 1053 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xac, 0x56, 0x59, 0x6f, 0xdb, 0x46,
	0x10, 0x0e, 0x75, 0xc5, 0x1a, 0x1f, 0x91, 0xd7, 0x97, 0xaa, 0xb6, 0x88, 0xca, 0xba, 0xae, 0x9a,
	0x06, 0x72, 0xec, 0x06, 0x68, 0x91, 0x1a, 0x05, 0x1c, 0xdb, 0x81, 0xed, 0x02, 0x76, 0xba, 0x32,
	0x92, 0x1e, 0x28, 0x58, 0x9a, 0x1c, 0xd9, 0x84, 0x45, 0x2e, 0x43, 0x2e, 0x9d, 0xfa, 0xb7, 0xf4,
	0xad, 0x3f, 0xa3, 0x8f, 0xfd, 0x55, 0x7d, 0x2c, 0xf6, 0xd0, 0x45, 0x52, 0x96, 0x0a, 0xf4, 0x6d,
	0xb9, 0xfb, 0xcd, 0xcc, 0x37, 0xb3, 0xf3, 0xcd, 0x12, 0x9e, 0x72, 0x0c, 0x62, 0x16, 0x75, 0x7b,
	0xec, 0xfd, 0xb6, 0xc3, 0x22, 0xdc, 0x0e, 0x23, 0xc6, 0xd9, 0x65, 0xd2, 0xdd, 0x46, 0xfb, 0x0a,
	0x23, 0x2b, 0xc6, 0xe8, 0xd6, 0x73, 0xb0, 0x2d, 0xb7, 0x49, 0x6d, 0x88, 0x6e, 0xcb, 0xf3, 0xc6,
	0x93, 0xb4, 0x7d, 0x37, 0xb2, 0x7d, 0x7c, 0xcf, 0xa2, 0x9b, 0x6d, 0x9b, 0xf3, 0xc8, 0xba, 0xb5,
	0x7b, 0x89, 0xb6, 0x6e, 0xec, 0x4c, 0xc6, 0xba, 0x28, 0xa2, 0x58, 0xc2, 0xc4, 0xbb, 0x4c, 0x38,
	0xc6, 0xda, 0xa4, 0x35, 0xd9, 0xa4, 0x9b, 0x04, 0x0e, 0xf7, 0x58, 0xa0, 0x91, 0x5b, 0x93, 0x91,
	0xea, 0x44, 0xe3, 0x9e, 0x4e, 0xc3, 0x59, 0xf1, 0xb5, 0x1d, 0xe2, 0xf4, 0xf8, 0xb7, 0x18, 0xc5,
	0x1e, 0x0b, 0xfa, 0x4c, 0x9f, 0x4d, 0x2c, 0xe4, 0xf0, 0x40, 0x56, 0x13, 0x35, 0x13, 0xf3, 0x18,
	0x08, 0x45, 0x9f, 0x71, 0xbc, 0x90, 0x80, 0x63, 0x3b, 0x70, 0x7b, 0x48, 0x56, 0xa0, 0xcc, 0x42,
	0xcb, 0x73, 0xeb, 0x46, 0xd3, 0x68, 0x15, 0x69, 0x89, 0x85, 0x27, 0x2e, 0xf9, 0x18, 0x80, 0x25,
	0x3c, 0x4c, 0xb8, 0x15, 0x24, 0x7e, 0xbd, 0xd0, 0x34, 0x5a, 0x65, 0x5a, 0x55, 0x3b, 0x67, 0x89,
	0x6f, 0xfe, 0x55, 0x80, 0xea, 0x79, 0x88, 0x91, 0x2d, 0xea, 0x41, 0x96, 0xa0, 0x30, 0x30, 0x2f,
	0x78, 0x2e, 0x21, 0x50, 0x0a, 0x6c, 0x1f, 0xa5, 0x59, 0x95, 0xca, 0x35, 0xd9, 0x83, 0x8a, 0x17,
	0x84, 0x09, 0x8f, 0xeb, 0xc5, 0x66, 0xb1, 0x35, 0xbf, 0xbb, 0xd9, 0x4e, 0xdf, 0x6c, 0x3b, 0xcb,
	0x8d, 0x6a, 0x1b, 0xb2, 0x09, 0x4b, 0x0e, 0x0b, 0x78, 0xc4, 0x7a, 0x96, 0xe4, 0x1a, 0xd7, 0x4b,
	0xcd, 0x62, 0xab, 0x48, 0x17, 0xf4, 0xee, 0x79, 0x78, 0xe2, 0xc6, 0x64, 0x0f, 0xca, 0xe2, 0x3e,
	0xe3, 0x7a, 0x59, 0x86, 0xd8, 0xca, 0x86, 0x18, 0x70, 0x6e, 0xef, 0x0b, 0xe0, 0x51, 0xc0, 0xa3,
	0x3b, 0xaa, 0x8c, 0xc8, 0x3a, 0x54, 0x54, 0x53, 0xd4, 0x2b, 0x92, 0xb7, 0xfe, 0x6a, 0x9c, 0x03,
	0x0c, 0xc1, 0xa4, 0x06, 0xc5, 0x1b, 0xbc, 0x93, 0xc9, 0x56, 0xa9, 0x58, 0x92, 0x2f, 0xa1, 0x2c,
	0x7b, 0x4e, 0xa6, 0x3b, 0xbf, 0xbb, 0x36, 0x1a, 0x55, 0x18, 0xbe, 0x11, 0x87, 0x54, 0x61, 0x5e,
	0x14, 0xbe, 0x31, 0xcc, 0x3f, 0x0d, 0xa8, 0xfe, 0x90, 0x60, 0x82, 0x27, 0x1c, 0x7d, 0xf2, 0x1a,
	0x6a, 0xd7, 0x32, 0x59, 0x8b, 0x33, 0xcb, 0x45, 0x27, 0xc2, 0xae, 0xf4, 0x3e, 0x63, 0x89, 0x8e,
	0x1f, 0xd0, 0x25, 0x65, 0x7f, 0xc1, 0x0e, 0xa5, 0x35, 0xf9, 0x16, 0xaa, 0xac, 0x9f, 0xa7, 0x26,
	0xf5, 0xe1, 0x3d, 0xa5, 0x38, 0x7e, 0x40, 0x87, 0xf8, 0x97, 0x15, 0x28, 0x79, 0x1c, 0x7d, 0xf3,
	0x00, 0x16, 0x25, 0x47, 0x8a, 0x71, 0xc8, 0x82, 0x18, 0xc9, 0x2e, 0x94, 0x65, 0x9f, 0xd6, 0x0d,
	0x59, 0xdc, 0x8f, 0x46, 0x3d, 0x2a, 0x42, 0x1d, 0x71, 0xfc, 0x5a, 0x74, 0x1a, 0x55, 0x50, 0xf3,
	0xef, 0x02, 0xac, 0x1e, 0x44, 0x68, 0x73, 0x3c, 0x60, 0x01, 0xc7, 0xdf, 0x39, 0xc5, 0x77, 0x09,
	0xc6, 0x9c, 0x3c, 0x07, 0x50, 0x9d, 0x69, 0xb9, 0x83, 0x74, 0xc7, 0x0a, 0xd7, 0x91, 0xa7, 0x87,
	0xd8, 0xa5, 0xd5, 0xb8, 0xbf, 0x24, 0xab, 0x50, 0xb6, 0xe3, 0xbb, 0xc0, 0x91, 0x49, 0xcd, 0x51,
	0xf5, 0x41, 0xb6, 0xe0, 0xd1, 0x0d, 0x62, 0x68, 0xd9, 0x3d, 0xef, 0x16, 0xad, 0x18, 0x1d, 0xd1,
	0x62, 0xa2, 0x15, 0x17, 0xc5, 0xf6, 0xbe, 0xd8, 0xed, 0xa0, 0x13, 0x93, 0xaf, 0x61, 0x5e, 0x2b,
	0x48, 0x06, 0x2d, 0xc9, 0xa0, 0xeb, 0xa3, 0x41, 0xdf, 0xa8, 0x63, 0x11, 0x15, 0x6e, 0x07, 0x6b,
	0xf2, 0x23, 0x7c, 0xe0, 0xf4, 0x92, 0x98, 0x4b, 0xb6, 0xa9, 0xa9, 0x51, 0xaf, 0x64, 0xab, 0x71,
	0x28, 0x41, 0xfb, 0x03, 0x0c, 0xdd, 0xd0, 0xe6, 0xe9, 0x03, 0xa1, 0x32, 0x47, 0x15, 0x46, 0xe8,
	0xef, 0x61, 0xd3, 0x68, 0x55, 0x68, 0x55, 0xef, 0x9c, 0xb8, 0xa7, 0xa5, 0xb9, 0x72, 0xad, 0x62,
	0x5e, 0xc3, 0x5a, 0xaa, 0x86, 0xfa, 0x46, 0x4e, 0x60, 0x39, 0xcb, 0xa7, 0x30, 0x03, 0x9f, 0x9a,
	0x9b, 0xda, 0x39, 0x2d, 0xcd, 0x19, 0xb5, 0x82, 0x79, 0x09, 0x4b, 0x47, 0xc1, 0x3b, 0x75, 0xeb,
	0xea, 0x9e, 0xc6, 0x09, 0x1a, 0x29, 0x82, 0x64, 0x07, 0xca, 0x12, 0xae, 0x35, 0x9d, 0xd3, 0x65,
	0x83, 0x3e, 0xa7, 0x0a, 0x69, 0xfe, 0x04, 0x8f, 0x06, 0x31, 0x74, 0x1e, 0xaf, 0x60, 0x49, 0x6e,
	0x58, 0x91, 0xde, 0xd1, 0x2d, 0xf6, 0x78, 0x82, 0xbb, 0xbe, 0x21, 0x5d, 0x1c, 0xf3, 0x63, 0x9e,
	0xc2, 0xea, 0x5b, 0xdb, 0xe3, 0x12, 0x73, 0xc8, 0x82, 0x59, 0x93, 0x18, 0xcc, 0xbf, 0x82, 0x1c,
	0x29, 0x72, 0xfe, 0x99, 0x1b, 0xb0, 0x96, 0xf2, 0xa5, 0x83, 0xec, 0x40, 0xed, 0xfb, 0x7e, 0x5b,
	0xcd, 0x16, 0xc0, 0x5c, 0x81, 0xe5, 0x11, 0x13, 0xed, 0xe7, 0x39, 0xac, 0x1c, 0xf4, 0x58, 0x9c,
	0x16, 0xc6, 0x14, 0x57, 0xeb, 0xb0, 0x3a, 0x6e, 0xa5, 0xbd, 0x71, 0xd8, 0xa0, 0x78, 0xe5, 0x89,
	0x26, 0x7b, 0xa5, 0x5f, 0xa9, 0x19, 0xb3, 0x7f, 0x01, 0x0b, 0xfd, 0x77, 0x4d, 0xca, 0x42, 0xcd,
	0x8b, 0x8d, 0xd1, 0xd2, 0xf7, 0x3d, 0x0a, 0x5d, 0xcc, 0x77, 0x87, 0x1f, 0x66, 0x03, 0xea, 0xd9,
	0xa8, 0x9a, 0xd1, 0x1f, 0x06, 0x2c, 0x77, 0x30, 0x70, 0xd5, 0x68, 0xf8, 0xef, 0x57, 0x31, 0x7c,
	0x8a, 0x76, 0xe0, 0xa1, 0x22, 0xd3, 0x7f, 0x3a, 0x36, 0xb2, 0xa3, 0x47, 0x4d, 0x9d, 0x3e, 0x8e,
	0x3c, 0x86, 0x79, 0xad, 0x0c, 0xf9, 0x0e, 0x95, 0xe4, 0xb0, 0x06, 0xb5, 0x75, 0x66, 0xfb, 0x68,
	0xae, 0x02, 0x19, 0x25, 0xa7, 0x38, 0xef, 0xfe, 0x53, 0x86, 0x85, 0x23, 0xd1, 0x67, 0x1d, 0xf5,
	0x0f, 0x42, 0x7e, 0x83, 0xc5, 0x31, 0xe9, 0x91, 0x9c, 0x27, 0x25, 0x6f, 0xbe, 0x35, 0x3e, 0x9f,
	0x8a, 0xd3, 0xbd, 0x7f, 0x06, 0x0f, 0xb5, 0x1c, 0x48, 0x33, 0x6b, 0x33, 0xae, 0xc6, 0xc6, 0x27,
	0xf7, 0x20, 0xb4, 0xbf, 0x5f, 0xa0, 0xd6, 0xe1, 0x11, 0xda, 0xbe, 0x17, 0x5c, 0xfd, 0x9f, 0x8e,
	0x5b, 0xc6, 0x33, 0x43, 0x94, 0x63, 0x4c, 0x14, 0x79, 0xe5, 0xc8, 0x53, 0x60, 0x5e, 0x39, 0x72,
	0xd5, 0x45, 0x2e, 0xa0, 0x3a, 0x90, 0x0a, 0x31, 0xb3, 0x56, 0x69, 0xe9, 0x35, 0x3e, 0xbd, 0x17,
	0xa3, 0xbd, 0xfe, 0x0a, 0x0b, 0xa3, 0xaa, 0x21, 0x9f, 0xe5, 0xdc, 0x4e, 0x56, 0x8b, 0x8d, 0xad,
	0x69, 0x30, 0xed, 0xde, 0x83, 0x5a, 0x5a, 0x06, 0xe4, 0x8b, 0xbc, 0xb7, 0x3b, 0x57, 0xa0, 0x8d,
	0x27, 0xb3, 0x40, 0x75, 0xa8, 0xb7, 0x00, 0xc3, 0xbe, 0x25, 0x39, 0xc9, 0x67, 0x24, 0xd7, 0xd8,
	0xbc, 0x1f, 0xa4, 0x1c, 0xbf, 0xfc, 0xee, 0xe7, 0xbd, 0x2b, 0x8f, 0x5f, 0x27, 0x97, 0x6d, 0x87,
	0xf9, 0x23, 0x3f, 0x90, 0x13, 0x96, 0x57, 0x6c, 0xfc, 0x97, 0xf3, 0xb2, 0x22, 0x57, 0x5f, 0xfd,
	0x1b, 0x00, 0x00, 0xff, 0xff, 0xfd, 0x54, 0x7a, 0xef, 0xde, 0x0b, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// EagerServiceClient is the client API for EagerService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type EagerServiceClient interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error)
	// A streaming version of Enqueue.
	// Current server implementation sends one response per received request.
	// The benefit for using a streaming version is that subsequent requests
	// can be sent without waiting for a response to the previous request. This
	// synchronization is required in the regular Enqueue call because gRPC does
	// not guarantee to preserve request order.
	StreamingEnqueue(ctx context.Context, opts ...grpc.CallOption) (EagerService_StreamingEnqueueClient, error)
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this.
	KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error)
	// Takes a FunctionDef and makes it enqueable on the remote worker.
	RegisterFunction(ctx context.Context, in *RegisterFunctionRequest, opts ...grpc.CallOption) (*RegisterFunctionResponse, error)
	// An RPC to push tensors to the server. At times, certain environments don't
	// allow the server to connect back to the client.
	SendTensor(ctx context.Context, in *SendTensorRequest, opts ...grpc.CallOption) (*SendTensorResponse, error)
}

type eagerServiceClient struct {
	cc *grpc.ClientConn
}

func NewEagerServiceClient(cc *grpc.ClientConn) EagerServiceClient {
	return &eagerServiceClient{cc}
}

func (c *eagerServiceClient) CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error) {
	out := new(CreateContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CreateContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error) {
	out := new(EnqueueResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/Enqueue", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) StreamingEnqueue(ctx context.Context, opts ...grpc.CallOption) (EagerService_StreamingEnqueueClient, error) {
	stream, err := c.cc.NewStream(ctx, &_EagerService_serviceDesc.Streams[0], "/tensorflow.eager.EagerService/StreamingEnqueue", opts...)
	if err != nil {
		return nil, err
	}
	x := &eagerServiceStreamingEnqueueClient{stream}
	return x, nil
}

type EagerService_StreamingEnqueueClient interface {
	Send(*EnqueueRequest) error
	Recv() (*EnqueueResponse, error)
	grpc.ClientStream
}

type eagerServiceStreamingEnqueueClient struct {
	grpc.ClientStream
}

func (x *eagerServiceStreamingEnqueueClient) Send(m *EnqueueRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *eagerServiceStreamingEnqueueClient) Recv() (*EnqueueResponse, error) {
	m := new(EnqueueResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *eagerServiceClient) WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error) {
	out := new(WaitQueueDoneResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/WaitQueueDone", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error) {
	out := new(KeepAliveResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/KeepAlive", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error) {
	out := new(CloseContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CloseContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) RegisterFunction(ctx context.Context, in *RegisterFunctionRequest, opts ...grpc.CallOption) (*RegisterFunctionResponse, error) {
	out := new(RegisterFunctionResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/RegisterFunction", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) SendTensor(ctx context.Context, in *SendTensorRequest, opts ...grpc.CallOption) (*SendTensorResponse, error) {
	out := new(SendTensorResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/SendTensor", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// EagerServiceServer is the server API for EagerService service.
type EagerServiceServer interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(context.Context, *CreateContextRequest) (*CreateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(context.Context, *EnqueueRequest) (*EnqueueResponse, error)
	// A streaming version of Enqueue.
	// Current server implementation sends one response per received request.
	// The benefit for using a streaming version is that subsequent requests
	// can be sent without waiting for a response to the previous request. This
	// synchronization is required in the regular Enqueue call because gRPC does
	// not guarantee to preserve request order.
	StreamingEnqueue(EagerService_StreamingEnqueueServer) error
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(context.Context, *WaitQueueDoneRequest) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this.
	KeepAlive(context.Context, *KeepAliveRequest) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(context.Context, *CloseContextRequest) (*CloseContextResponse, error)
	// Takes a FunctionDef and makes it enqueable on the remote worker.
	RegisterFunction(context.Context, *RegisterFunctionRequest) (*RegisterFunctionResponse, error)
	// An RPC to push tensors to the server. At times, certain environments don't
	// allow the server to connect back to the client.
	SendTensor(context.Context, *SendTensorRequest) (*SendTensorResponse, error)
}

// UnimplementedEagerServiceServer can be embedded to have forward compatible implementations.
type UnimplementedEagerServiceServer struct {
}

func (*UnimplementedEagerServiceServer) CreateContext(ctx context.Context, req *CreateContextRequest) (*CreateContextResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method CreateContext not implemented")
}
func (*UnimplementedEagerServiceServer) Enqueue(ctx context.Context, req *EnqueueRequest) (*EnqueueResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Enqueue not implemented")
}
func (*UnimplementedEagerServiceServer) StreamingEnqueue(srv EagerService_StreamingEnqueueServer) error {
	return status.Errorf(codes.Unimplemented, "method StreamingEnqueue not implemented")
}
func (*UnimplementedEagerServiceServer) WaitQueueDone(ctx context.Context, req *WaitQueueDoneRequest) (*WaitQueueDoneResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method WaitQueueDone not implemented")
}
func (*UnimplementedEagerServiceServer) KeepAlive(ctx context.Context, req *KeepAliveRequest) (*KeepAliveResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method KeepAlive not implemented")
}
func (*UnimplementedEagerServiceServer) CloseContext(ctx context.Context, req *CloseContextRequest) (*CloseContextResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method CloseContext not implemented")
}
func (*UnimplementedEagerServiceServer) RegisterFunction(ctx context.Context, req *RegisterFunctionRequest) (*RegisterFunctionResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method RegisterFunction not implemented")
}
func (*UnimplementedEagerServiceServer) SendTensor(ctx context.Context, req *SendTensorRequest) (*SendTensorResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method SendTensor not implemented")
}

func RegisterEagerServiceServer(s *grpc.Server, srv EagerServiceServer) {
	s.RegisterService(&_EagerService_serviceDesc, srv)
}

func _EagerService_CreateContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CreateContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CreateContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CreateContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CreateContext(ctx, req.(*CreateContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_Enqueue_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(EnqueueRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).Enqueue(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/Enqueue",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).Enqueue(ctx, req.(*EnqueueRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_StreamingEnqueue_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(EagerServiceServer).StreamingEnqueue(&eagerServiceStreamingEnqueueServer{stream})
}

type EagerService_StreamingEnqueueServer interface {
	Send(*EnqueueResponse) error
	Recv() (*EnqueueRequest, error)
	grpc.ServerStream
}

type eagerServiceStreamingEnqueueServer struct {
	grpc.ServerStream
}

func (x *eagerServiceStreamingEnqueueServer) Send(m *EnqueueResponse) error {
	return x.ServerStream.SendMsg(m)
}

func (x *eagerServiceStreamingEnqueueServer) Recv() (*EnqueueRequest, error) {
	m := new(EnqueueRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func _EagerService_WaitQueueDone_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(WaitQueueDoneRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/WaitQueueDone",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, req.(*WaitQueueDoneRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_KeepAlive_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KeepAliveRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).KeepAlive(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/KeepAlive",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).KeepAlive(ctx, req.(*KeepAliveRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_CloseContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CloseContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CloseContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CloseContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CloseContext(ctx, req.(*CloseContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_RegisterFunction_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RegisterFunctionRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).RegisterFunction(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/RegisterFunction",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).RegisterFunction(ctx, req.(*RegisterFunctionRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_SendTensor_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SendTensorRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).SendTensor(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/SendTensor",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).SendTensor(ctx, req.(*SendTensorRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _EagerService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "tensorflow.eager.EagerService",
	HandlerType: (*EagerServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateContext",
			Handler:    _EagerService_CreateContext_Handler,
		},
		{
			MethodName: "Enqueue",
			Handler:    _EagerService_Enqueue_Handler,
		},
		{
			MethodName: "WaitQueueDone",
			Handler:    _EagerService_WaitQueueDone_Handler,
		},
		{
			MethodName: "KeepAlive",
			Handler:    _EagerService_KeepAlive_Handler,
		},
		{
			MethodName: "CloseContext",
			Handler:    _EagerService_CloseContext_Handler,
		},
		{
			MethodName: "RegisterFunction",
			Handler:    _EagerService_RegisterFunction_Handler,
		},
		{
			MethodName: "SendTensor",
			Handler:    _EagerService_SendTensor_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamingEnqueue",
			Handler:       _EagerService_StreamingEnqueue_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "tensorflow/core/protobuf/eager_service.proto",
}
